# Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review

[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FDL4mHealth%2FContrastive-Learning-in-Medical-Time-Series-Survey&count_bg=%2325DAA4&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
<!-- ![GitHub Repo stars](https://img.shields.io/github/stars/DL4mHealth/Contrastive-Learning-in-Medical-Time-Series-Survey?style=social)
![GitHub forks](https://img.shields.io/github/forks/DL4mHealth/Contrastive-Learning-in-Medical-Time-Series-Survey?style=social)
 -->
This is for the survey paper **Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review** which was published in *Sensors* in 2023. 


### Authors: Ziyu Liu (ziyu.liu2@student.rmit.edu.au), Azadeh Alavi (azadeh.alavi@rmit.edu.au), Minyi Li (liminyi0709@gmail.com) and Xiang Zhang (xiang.zhang@uncc.edu)

### [Paper link](https://www.mdpi.com/1424-8220/23/9/4221)

## Summary:   
We carefully reviewed 43 papers in the field of self-supervised contrastive learning for medical time series. Specifically, this paper outlines the pipeline of contrastive learning, including pre-training, fine-tuning, and testing. We provide a comprehensive summary of the various augmentations applied to medical time series data, the architectures of pre-training encoders, the types of fine-tuning classifiers and clusters, and the popular contrastive loss functions. Moreover, we present an overview of the different data types used in medical time series, highlight the medical applications of interest, and provide a comprehensive table of 51 public datasets that have been utilized in this field. In addition, this paper will provide a discussion on the promising future scopes such as providing guidance for effective augmentation design, developing a unified framework for analyzing hierarchical time series, and investigating methods for processing multimodal data. Despite being in its early stages, self-supervised contrastive learning has shown great potential in overcoming the need for expert-created annotations in the research of medical time series.

## This repo includes:  
* The implementation of time series augmentations (Timeseries_augmentations.ipynb) file, this file augments the time series data at sample-level. We will release the code that can achieve augmentation at batch-level and dataset-level later.     
* An extended summary table of the 43 reviewed papers, including title, author/year, challenges, contributions, scenario/task/findings, datasets, preprocessing/perturbation, model, performance and link to their implementation codes (if publically released). 

## Citation
If you find this paper useful for your research, please consider citing it:

```
  @Article{liuself2023survey,
    AUTHOR = {Liu, Ziyu and Alavi, Azadeh and Li, Minyi and Zhang, Xiang},
    TITLE = {Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review},
    JOURNAL = {Sensors},
    VOLUME = {23},
    YEAR = {2023},
    NUMBER = {9},
    DOI = {10.3390/s23094221}
    }
```


## Extended summary table:
| Title  	| Author (Year) 	| Challenge 	| Contribution 	| Scenario/task/findings 	| Datsets 	| Preprocessing/perturbation 	| Model 	| Performance 	| Code 	|
|:---:	|---	|---	|---	|---	|---	|---	|---	|---	|---	|
| First Steps <br>Towards <br>Self-Supervised <br>Pretraining <br>of the <br>12-Lead ECG 	| Gedon et al. <br>(2022) 	| Discover a supervision signal from the data itself for self-supervised represenation learning 	| 1) Define a self-supervised learning task and pretraining procedure which <br>can learn generalizable features of ECG data, <br>2) Develop and show that a ResNet based architecture can successfully be <br>used in combination with our learning task.  	| ECG reconstruction and <br>(anomalies)classification; <br>Pretraining on the CODE <br>training dataset, <br>Use transfer learning <br>with the ECG benchmarks: <br>PTB-XL and CPSC dataset; 	| CODE, <br>CPSC 2018, <br>PTB-XL 	|  	| U-ResNet: <br>ResNet + encoder-decoder <br>+ channel-wise dense layer<br> + U-Net based skip-connections.  <br>Downstream task(classification): <br>encoder (no bottleneck layer, <br>no U-Net skip connections) + <br>linear classifier  	| AUCÔºö<br>CPSC: <br>+PT: <br>0.954; <br><br>PTB-XL:<br>+PT: <br>0.919 	| - 	|
| Self-supervised <br>representation <br>learning from <br>12-lead ECG data 	| Mehari et al. (2022) 	| Label scarcity in ECG data 	| 1. Comprehensive assessment of self-supervised representation learning for <br>12-lead ECG data to foster measurable progress.<br>2. Compare instance-based self-supervised methods and contrastive <br>forecasting methods.<br>3. Modify the CPC architecture and training procedure for <br>performance improvements.<br>4. Evaluate downstream classifiers finetued from self-supervised models to <br>training from scratch. 	| Assessment of self-supervised <br>representation learning from <br>clinical 12-lead ECG data:<br>-data efficiency <br>(downstream performance <br> number of folds used <br>in finetuning);<br>-quantitative performance <br>(macro AUC);<br>-robustness <br>(influence of physiological <br> on downstream performance) 	| Pretraining:<br>CinC2020,<br>Chapman,<br>Ribeiro<br><br>Evaluation:<br>PTB-XL 	|  	| Modified CPC (4FC+2LSTM+2FC);<br><br>Compared with:<br>Supervised (4FC+2LSTM+2FC)<br>Supervised (xresnet1d50)<br>SimCLR(RRC, TO)(xresnet1d50)<br>SimCLR physio(xresnet1d50)<br>BYOL(RRC,TO)(xresnet1d50)<br>BYOL physio. (xresnet1d50)<br><br>*Physiological noise, <br>(RRC, TO) are transformations 	| Macro AUC<br>(on PTB-XL):<br><br>Modified <br>CPC:<br>Linear:<br>0.9272<br>fine-tuned:<br>0.9418<br><br> 	| [Link](https://github.com/hhi-aml/ecg-selfsupervised) 	|
| Semi-Supervised <br>Contrastive Learning <br>for Generalizable <br>Motor Imagery <br>EEG Classification 	| Han et al.<br>(2021) 	| Label scarcity in ECG data 	| 1. A semi-supervised framework with a combination of self-supervised <br>contrastive learning and adversarial training.<br>2. Semi-supervised learning structure with contrastive learning for <br>unlabelled data.<br>3. Adversarial training to disentangle the subject/session-specific <br>information from the desired MI information in the latent representation. 	|  	| BCIC IV 2a<br> MI-EEG dataset <br>from the <br>MOABB library 	| Filtered between 4Hz and 40Hz, <br>converted it into microvolt. <br>all 22 channels of the EEG <br>and the entire 4 seconds of <br>the trial windows. T<br>he EEG windows were then <br>resampled from 250Hz to <br>128Hz resulting in a length<br>of 512 sample points for <br>each window and processed <br>through channel-wise z-score <br>normalisation. 	| Augmentation-based contrastive loss<br>+ task classification loss + <br>domain discriminator loss <br>EEGNet, DeepConvNet as the encoder 	| Semi-Deep<br>ConvNet:<br>10%: 67.6<br>20%: 74.3<br>50%: 77.4<br>100%: 79.4 	| - 	|
| Self-Supervised <br>Representation <br>Learning <br>from <br>Electroence-<br>phalography <br>Signals 	| Banville et al.<br>(2019) 	| Supervised models are limited by the cost - and<br>sometimes the impracticality - of data collection and labeling 	| 1. Propose self-supervised strategies to learn end-to-end features from <br>unlabeled time series such as EEG. <br>2. Two temporal contrastive learning tasks refer to as ‚Äúrelative positioning‚Äù <br>and ‚Äútemporal shuffling‚Äù. <br>3. On a downstream sleep staging task, outperform traditional unsupervised <br>and purely supervised approaches, specifically in low-data regimes. 	| Demonstrate that contrastive <br>learning tasks based on <br>predicting whether time windows <br>are close in time can be used <br>to learn EEG features that <br>capture multiple components <br>of the structure underlying <br>the data (time windows close <br>in time should share the <br>same label) 	| Sleep EDF,<br>MASS session3 	| Both:raw EEG ->4th-order FIR <br>lowpass filter (20-Hz cutoff <br>frequency and Hamming window)<br>MASS: downsampled to 128Hz, <br>extracted non-overlapping <br>30-s windows, windows were <br>normalized <br>(to focus on Fz,Cz and Oz <br>channels.) 	| Pre-tain: sample pairs of <br>time windows (RP: x_t,x_t'; <br>TS: triplets: x_t, x_t', x_t'')<br> + feature extractor (CNN) + <br>contrastive module aggregate <br>the feature representation of<br>each window (element-wise <br>absolute difference)<br><br>Finetuning: feature extractor (CNN) <br>+ linear context discriminative model 	| Average <br>per-class <br>recall:<br>RP: 76.66<br>TS: 75.9<br><br>EEG <br>features: <br>79.43<br>Fully <br>supervised: <br>72.51 	| - 	|
| Anomaly Detection <br>on <br>Electroence-<br>phalography <br>with <br>Self-supervised <br>Learning<br> 	| Xu et al.<br>(2020) 	| 1. Hand crafted features could omit potentially discriminative feature;<br>2. Labeling of EEG signals of the state of epilepitc seizures have become bottleneck in applying deep learning;<br>3. Individual differences of patients with epilepsy and certain abnormal brain activities share with other brain dieases. generalize issue 	| 1. A new self-supervised learning method based on only normal EEG data <br>is proposed particularly for detection of any abnormal signal in EEG data.<br>2. A simple and effective method is proposed to generate the self-labeled data <br>for self-supervised learning,  in which different labels correspond to different <br>scaling transformations on EEG data.<br>3. Performs significantly better than existing wellknown anomaly <br>detection approaches, and is robust to varying model structures <br>and hyperparameters settings. 	| Higher-frequency signals <br>in an abnormal EEG data would <br>probably mislead <br>the classifier to predict an <br>incorrect scaling transformation. 	| UPenn and <br>Mayo Clinic's <br>seizure detection <br>challenge dataset 	| Generation of self-labeled <br>EEG data:<br>Each sequence of EEG data <br>matrix X_i -> K scalling <br>transformations -> a longer <br>sequence s_k *d (number of <br>values in the original sequence)<br>-> for each scale s_k, all <br>the formed new sequences <br>are collected to form a new <br>scaled EEG data T_k(X_i) 	| CNN classifier for prediction <br>of scaling transformations:<br>Input: self-labeled dataset;<br>Output: K values, each <br>representing the probability <br>of one scaling transformation.<br>Cross entropy -> classifier <br>output, ground truth scaling <br>transformation (one-hot vector)<br><br>Anomaly detection:<br>Difference between predicted <br>scaling and ground truth scaling <br>indicates the degree of abnomality<br>of new EEG 	| AUC:<br>ResNet34: <br>0.941<br><br>Ablition <br>study on <br>kernel shapes<br>(this paper <br>proposed 3*3 <br>compared to <br>1*3):<br>Backbone:<br>ResNet34: <br>0.943<br>VGG19: <br>0.960  	| - 	|
| Contrastive Representation <br>Learning for Electroencephalogram <br>Classification 	| Mohsenvand et al.<br>(2020) 	| Hand-crafted feature; deep learning in supervised manner restricts the use of learned features to specific task; labeling EEG is cumbersome and requires years of medical training and experimental design; labeled EEG data is limited and existing dataset are small; existing dataset use incompatible EEG setups (different number of channels, sampling rates, types of sensors, etc.) hard to fuse to larger dataset for unsupervised learning. 	| 1. Combine multiple EEG datasets,<br>2. Use the uderlying physics of EEG signals to multiply <br>the number of samples (quadratic increase), <br>3. Learn representations in a self-supervised manner via <br>contrastive learning without requiring labels. 	| 1. Emotion recognition.<br>2. Normal/abnormal classification.<br>3. Sleep-stage scoring. 	| 1. SEED dataset <br>(ER)<br>2. TUH dataset <br>(NAC)<br>3. SleepEDF<br>(SSS) 	| Channel recombination: <br>By subtracting two channels, <br>one obtains a new channel <br>that represents the voltage <br>difference between the two <br>sensors, resulting in another <br>physiologically valid channel.<br>Preprocessing: resampled all <br>datasets to 200Hz and applied <br>a fifth-order band-pass <br>Butterworth filter (0.3-80 Hz).  <br>removed the channels that <br>involved voltages higher <br>than 500 ŒºVs as they normally <br>represent artifacts. <br>To train the encoder, <br>cut the channels into <br>chunks of 20 seconds 	| Channel augmenter: each channel, <br>randomly applies two of the <br>augmentations to form a positive pair.<br>Channel encoder: recurrent encoder,<br>convolutional encoder.<br>Projector: downsampling and bidirectional<br> LSTM units--each direction output <br>concatenated and fed into dense <br>layers with a ReLU activation in between.<br>Contrastive loss: NT-Xent.<br><br>Downstream tasks: Classifier: discard <br>the projector and use a classifier <br>almost identical to the projector:  	| fine-tuned <br>SeqCLR:<br>1. (C) 50%: <br>85.21<br><br>2. (C) 50%: <br>87.21<br><br>3. (R) 50%: <br>83.72 	| - 	|
| Forecasting adverse surgical <br>events using self-supervised <br>transfer learning for <br>physiological signals 	| Chen et al.<br>(2021) 	| 1. Availability of training data, lack sufficient data or computational resources.<br>2. Patient privacy considerations mean that large public EHR datasets are unlikely, leaving many institutions wiht insufficient resources to train performant models on their own. 	| Improves predictive accuracy by leveraging deep learning to embed <br>physiological signals. using LSTMs, embeds physiological signals <br>prior to forecasting adverse events with a downstream model. <br>Shares models rather than data to address data <br>insufficiency and improves over alternative methods. <br>By transferring performamt models as has been done in medical <br>images and clinical text, scientists can collaborate to improve <br>the accuracy of predictive model without exposing patient data.   	| Utilize fifteen physiological signal <br>variables and six static variable <br>inputs to forecast six possible <br>outcomes: hypoxemia, hypocapnia, <br>hypotension, hypertension,<br>phenylephrine administration, <br>and epinephrine administration. 	| Two OR datasets <br>(private)<br><br>ICU dataset <br>(MIMIC dataset) 	|  	| LSTM for representation learning, <br>followed by fully connected layer as <br>downstream predictor. Use observations<br> in previous 1 hour to predict next 5 mins.  	| - 	| [Link](https://github.com/suinleelab/PHASE) 	|
| T-DPSOM: An Interpretable <br>Clustering Method for <br>Unsupervised Learning <br>of Patient Health States 	| Manduchi et al.<br>(2021) 	| Traditional clustering methods have poor performance on high-dimensionality dataset -> dimensionality reduction and deature transformation to obtain low-dimentional representation of the raw data (easier to cluster) -> cluster feature lie in a latent space, can not be easily visualized or interpreted or investigating the relationship between clusters. Self-Organizing Map is a clustering method that provides such an interpretable representation. 	| 1. A deep clustering architecture conbines a VAE with a novel SOM-based <br>clustering objective.<br>2. An extension of this architecture to time series, improving clustering <br>performance, enabling temporal forecasting.<br>3. Showing superior performance on static image data and medical time series (ICU).<br>4. Cluster patientis into different sub-phenotypes and gain better understanding <br>of disease patterns and individual patient health states. 	| A useful tool to understand and<br>track patient health states in the ICU. 	| MNIST,<br>Fashion-MNIST,<br>eICU dataset 	| For eICU: use vital sign(d=14)<br> and lab measurements(d=84) <br>resampled to a 1-hour based <br>grid using forward filling <br>with population statistics <br>from training set if no <br>measurements were available <br>prior to the time point. <br>From ICU stays: <br>3 days<include< 30days, <br>or has gap in continuous <br>vital sign monitoring. <br>Overall data dimension d=98.<br>The last 72 hours of <br>multivariate time series <br>were used for the experiments. <br>As labels, use a variant of <br>the current dynamic APACHE. 	| A data point ùë•ùëñ is mapped to a continuous<br> embedding ùëßùëñ using a VAE. In T-DPSOM,<br> the embeddings ùëßùëñ,ùë° for ùë° = 1,...,ùëá are<br> connected by an LSTM, which predicts <br>the embedding ùëßùë° +1 of the next time step. 	| clustering <br>NMI:<br>0.1115<br>+-0.0006 	| [Link](https://github.com/ratschlab/dpsom) 	|
| CLOCS: Contrastive Learning <br>of Cardiac Signals Across <br>Space, Time, and Patients 	| Kiyasseh et al.<br>(2021) 	|  	| 1. Propose a family of patient-specific contrastive learning methods, that exploit <br>both temporal and spatial information present in ECG signals.<br>2. Outperforms state-of-the-art methods, BYOL and SimCLR, when performing a linear <br>evaluation of, and fine-tuning on, downstream tasks involving cardiac arrhythmia <br>classification. 	| Downstream task: cardiac <br>arrhythmia classification<br><br>Human physiology where abrupt <br>changes in cardiac function <br>(on the order of seconds)<br>are unlikely to occur.<br>multiple leads <br>(collected at the same time)<br>will reflect the same <br>underlying cardiac function. 	| PhysioNet 2020,<br>Chapman,<br>PhysioNet 2017,<br>Cardiology 	| Gaussian, Flip, SpecAugment 	| Pre-train: Contrastive Multi-segment<br> Coding; Contrastive Multi-lead Coding,<br>Contrastive Multi-segment Multi-lead Coding<br><br>Downstream task: 1)Linear Evaluation of <br>representation (pre-train, fine-tune same<br> dataset); 2)Transfer capabilities of <br>representations (pre-train, fine-tune<br> different dataset) 	| AUC:<br>1)CMSC<br>(Chapman): <br>0.896+-0.005<br>CMSC<br>(PhysioNet2020): <br>0.715+-0.033<br>2)CMSC(<br>Chapman+<br>PhysioNet2020): <br>0.83+-0.002<br>CMSC<br>(PhysioNet2020+<br>Chapman): <br>0.932+-0.008<br>CMSMLC<br>(PhysioNet2020+<br>PhysioNet2017):<br>0.774+-0.012  	| [Link](https://github.com/danikiyasseh/CLOCS) 	|
| Segment Origin Prediction: <br>A Self-supervised Learning <br>Method for Electrocardiogram <br>Arrhythmia Classification 	| Luo et al. (2021) 	| 1. Lack of well-annotated labels,<br>2. Compared to random weight initlization, pre-trained model weights can help to allivate overfitting 	| Develop a new augmentation: reorganization.  	| Single-lead ECG classification: <br>heart arrithmia detection 	| PhysioNet2017, <br>CPSC2018 	| Discrete wavelet <br>transform (DWT) for <br>denoising 	| One framework with 6 different methods <br><br>as encoder structure. <br>Innovation: a new <br>augmentation (reorganization). <br>Take two ECG segments/peaks <br>from a pool of segments: <br>if the two taken segments are from <br>the same recording, assign it psudo label 1;<br>otherwise, assign psudo label 0.<br><br>A classifier for psudo label prediction<br>serves as supervision signal for pretraining.  	| PhysioNet2017 <br>for pre-train; <br>CPSC2018 for <br>fine-tuning/<br>test. <br>F1 score: <br>0.875 	| - 	|
| Learning Unsupervised <br>Representations for <br>ICU Timeseries 	| Weatherhead et al.<br>(2022) 	| 1. Lack of labels in ICU time series<br>2. Allivate the effect of severe data imbalance 	| 1. Improved TNC model by using autocorrelation encoding-based neighborhood defining.<br>2. Overcame the negative sampling bias, i.e., the selected negative sample <br>(far away from target sample) could have the same label with the target sample 	| ICU scenarios: mortality, <br>diagnostic groups, circulatory <br>failure, cardiopulmonary arrest 	| HiRID dataset <br>(public), <br>High-frequency <br>ICU (private) 	|  	| Based on TNC: neighboring samples are<br>regarded as positive, otherwise negative.<br>The neighborhood is calculated/defined by <br>autocorrelation encoding (based on <br>Pearson correlation) 	| F1 score: <br>0.59 in HiRID <br>mortality; <br>0.61 in <br>diagnostic <br>group, 0.56 <br>in <br>circulatory <br>failure, <br>0.77 in <br>cardiopulmonary <br>arrest 	| - 	|
| CROCS: Clustering and <br>Retrieval of <br>Cardiac Signals <br>Based on Patient <br>Disease <br>Class, Sex, and Age 	| Kiyasseh et al.<br>(2021) 	| Given a large, unlabelled clinical database, <br>1. How do we extract attribute information from such unlabelled instances?  <br>2. How do we reliably search for and retrieve relevant instances? 	| 1. A supervised contrastive learning framework, attracts representations <br>of cardiac signals associated with a unique set of patient attributes <br>to embeddings, entitled clinical prototypes. <br>2. Outperforms DTC, in the clustering setting and retrieves relevant <br>cardiac signals from a large database. At the same time, <br>clinical prototypes adopt a semantically meaningful arrangement and <br>thus confer a high degree of interpretability. 	| Clinical representation learning <br>and clustering(setting 1),<br>Clinical information <br>retrieval(setting 2) 	| Chapman,<br>PTB-XL 	| Chapman: cardiac arrhythmia<br>labels-> group into 4 major <br>classes<br>PTB-XL: disease label -> <br>group into 5 major classes.<br>Each dataset contains patient <br>sex and age information and <br>is split, at the patient level, <br>into training, validation, <br>and test sets. Each time-series <br>recording is split into <br>non-overlapping segments of <br>2500 samples (‚âà 5s in duration), <br>as this is common for <br>in-hospital recordings. 	| Supervised clustering. ResNet18 	| Clustering:<br>1. cardiac <br>arrhythmia <br>class attribute:<br>CP CROCS(<br>Chapman) <br>acc: 90.3:<br>CP CROCS<br>(PTB-XL) <br>acc: 76.0<br>2. Sex and age <br>attributes:<br>Chapman: CP <br>CROCS(sex):<br>57.4; (age): <br>38.0<br>PTB-XL: CP <br>CROCS(sex): <br>73.5; TP <br>CROCS(age): <br>39.4<br>Retrieval:<br>check paper 	| - 	|
| Self-Supervised Graph <br>Neural Networks for <br>Improved <br>Electroencephalographic <br>Seizure Analysis 	| Tang et al.<br>(2022) 	| 1. Representing non-Euclidean data structure in EEGs, <br>2. Accurately classifying rare seizure types, <br>3. Lacking a quantitative interpretability approach to measure model ability to localize seizures. 	| 1. Representing the spatiotemporal dependencies in EEGs using a GNN and <br>proposing two EEG graph structures that capture the electrode geometry <br>or dynamic brain connectivity, <br>2. Proposing a self-supervised pre-training method that predicts preprocessed <br>signals for the next time period to further improve model performance, <br>particularly on rare seizure types, <br>3. Proposing a quantitative model interpretability approach to assess a <br>model‚Äôs ability to localize seizures within EEGs.  	| Seizure detection and <br>classification<br><br>Use self-supervised pre-training: <br>predict future 12 seconds to learn <br>task-agnostic representations and <br>improve downstream task (detection <br>and classification) performance 	| Temple <br>University <br>Hospital EEG <br>Seizure Corpus <br>(TUSZ),<br>a in-house dataset 	| Transform raw EEG to the <br>frequency domain, and obtain <br>the log-amplitudes of the <br>fast Fourier transform of <br>raw EEG signals.<br>Detection and self-supervised <br>pre-training: use both seizures <br>and non-seizure EEGs, obtain <br>the 12-s(60-s)EEG clips <br>non-overlapping 12-s(60-s) <br>sliding windows.<br>Classification: use only <br>seizure EEGs and obtain one <br>12-s(60-s) EEG clips from <br>each seizure event(such that <br>each EEG clip had exactly <br>one seizure type), use a <br>refined seizure classification <br>scheme: four seizure <br>classes in total. 	| Augmentation: a) randomly scaling, <br>b) randomly reflecting the signals <br>along the scalp midline.<br><br>Distance graph: represents the natural<br> geometry of EEG electrodes, <br>compute edge weight by applying <br>a thresholded Gaussian kernel <br>to the pairwise Euclidean distance<br> between electrodes.<br>Correlation graph: capture dy<br>namic brain connectivity, define <br>the edge weight as the absolute <br>value of the normalized cross-correlation<br>between the preprocessed signals.<br><br>Encoder: DCGRU-Diffusion <br>Convolutional Gated Recurrent Units 	| With <br>pre-training:<br>Seizure <br>detection <br>AUROC:<br>Dist-<br>DCRNN(12s): <br>0.866+-0.016<br>Dist-<br>DCRNN(60s): <br>0.875+-0.016<br><br>Seizure <br>classification <br>weighted <br>F1-score:<br>12s:<br>Dist-DCRNN: <br>0.746+-0.024<br>60s:<br>Corr-DCRNN: <br>0.749+-0.017<br>Dist-DCRNN: <br>0.749+-0.028 	| [Link](https://github.com/tsy935/eeg-gnn-ssl) 	|
| Domain-guided <br>Self-supervision <br>of EEG Data <br>Improves Downstream <br>Classification <br>Performance <br>and <br>Generalizability 	| Wagh et al.<br>(2021) 	| Can we make encoders learn desirable physiological or pathological features through bespoke pretext tasks?  	| 1. Propose SSL tasks for EEG based on the spatial similarity of brain activity, <br>underlying behavioral states, and age-related differences; <br>2. Present evidence that an encoder pretrained using the proposed SSL tasks shows <br>strong predictive performance on multiple downstream classifications; <br>3. Using two large EEG datasets, show encoder generalizes well to multiple EEG <br>datasets during downstream evaluations. 	| Downstream tasks:<br>EEG grade(normal, abnormal), <br>eye state(eye open, eyes closed), <br>age(young, old), and <br>gender(male, female) <br>classification 	| TUH EEG Abnormal <br>Corpus(TUAB),<br>MPI LEMON 	| Pre-text task:<br>Hemipheric symmetry(HS): <br>aug1-randomly flipping, <br>aug2-add Gaussian noise;<br>Behavioral state <br>estimation(BSE): <br>DBR-delta-beta power <br>ratio(proxy measure of <br>the subjects's <br>behavioral state);<br>Age contrastive(AC): <br>a triplet training tuple <br>constructed from 3 EEG <br>epochs:(X,X+,X_), <br>similarity measured by <br>Euclidean distance, <br>triplet loss. <br>(same age group <br>labeled similar). 	| Pre-training:<br>represented the EEG epochs by <br>2D images (topographical map of <br>the spectral power in a brain rhythm band)<br>->Resnet-18 backbone(feature extractor)<br>->three linear layers(projector) <br>-> three SSL pre-text task layer<br>-> multi-task loss<br><br><br>Fine-tuning:<br>(Resnet-18 backbone -> linear layer) <br>x 4 (four dowmstream tasks) 	| Binary classification <br>(AUC):<br>TUH:<br>BSE only<br>(eeg grade): <br>0.918(3e-4)<br>LEMON:<br>BSE-AC(Age): <br>0.987(1e-3)<br>HS-BSE-AC<br>(Gender): <br>0.803(8e-3) 	| [Link](https://github.com/neerajwagh/eeg-self-supervision) 	|
| CLECG: A Novel <br>Contrastive Learning <br>Framework for <br>Electrocardiogram <br>Arrhythmia <br>Classification 	| Chen et al, (2021) 	| Lack of annontations in ECG 	| Contrastive learning framework for ECG pre-training 	| Heart arrhythmia detection 	| PTB-XL for <br>traning, <br>ICBEB2018 <br>and <br>PhysioNet 2017<br>for fine-tuning 	|  	| Augmentation: <br>Daubechies wavelet transform, <br>random crop/drop. <br><br>Encoder: xresnet101 backbone<br> +MLP projection head 	| F1 0.788 for <br>PhysioNet2017; <br>0.942 (F1) <br>on ICBEB2018 	| - 	|
| Self-Supervised <br>Learning with <br>Electrocardiogram <br>Delineation for <br>Arrhythmia Detection 	| Lee et al., (2021) 	| Lack of annontations in ECG 	| Propose a mixed schematic diagram by combining self-supervised representations <br>and manually extracted features for ECG delineation 	| Heart arrhythmia detection 	| CPSC, <br>PT-BXL, <br>Shaoxing-Chapman 	|  	| m-ResNet architecture 	| F1:<br>With 10% <br>labels, <br>69.18 for <br>CPSC, <br>66.86 for <br>PTB, <br>81.49 for <br>Shaoxing 	| - 	|
| Towards Parkinson‚Äôs <br>Disease Prognosis <br>Using Self-Supervised <br>Learning and <br>Anomaly Detection 	| Jiang et al.<br>(2021) 	| 1. No enough label to detect PK<br>2. PD is chronic disease that last for long time, the positive samples could be very diverse as they are collected span a long period.  	| Form PD detection as a task of anomaly detection. Use contrastive learning <br>to learn representations unsupervisely, <br>then detect PD with anomaly detection model. 	| PD detection 	| mPower data 	| Sensory signals are <br>downsampled to 10% <br>of original sampling <br>rate, to reduce <br>high frequency noise 	| CPC for SSL pre-training, <br>One-Class Deep SVDD for <br>anomaly detection.  	| AUC: 67.3 	| - 	|
| Detection of maternal <br>and fetal stress from <br>the electrocardiogram<br>with self-supervised <br>representation<br>learning 	| Sarkar et al.<br>(2021) 	| DL's utility in non-invasive biometric monitoring during pregnancy not well studied 	| 1. Validated the chronic stress exposure by psychological inventory, <br>maternal hair cortisol and FSI(Fetal Stress Index). <br>2. Tested two variants of SSL architecture, one trained on the generic <br>ECG features for emotional recognition obtained from public datasets and <br>another transfer learned on private data. 3. Provides a novel source of <br>physiological insights into complex multi‚Äêmodal relationships between <br>different regulatory systems exposed to chronic stress.  	| Detection of maternal and <br>fetal stress from abdominal <br>ECG (the aECG was deconvoluted <br>into fetal and maternal <br>ECG-fECG, mECG)  	| AMIGOS,<br>DREAMER,<br>WESAD,<br>SWELL,<br>FELICITy <br>(private) 	| Performed minimal <br>pre-processing on <br>the raw data. <br>re-sampled ECG signals <br>to a sampling frequency <br>to 256 Hz, segmentation <br>into 10-s windows. <br>To remove the noisy <br>parts of aECG and mECG <br>data, utilized the SQI <br>values available with <br>the segments, SQI < 0.5 <br>were discarded. resulted <br>in removing approximately <br>4.1% of total acquired <br>data with a standard <br>deviation. 	| Transformations: noise addition, <br>scaling, negation, temporal inversion, <br>permutation, time-warping<br>1. Signal transformation recognition<br> network (pre-train)<br>Transformed ECG -> three convolutional<br> blocks, each consists of two 1<br>D convolution layers with ReLU <br>and a max pooling layer <br>-> global max pooling <br>-> several fully connected layers<br>2. Affective recognition network <br>(fine-tune) Raw ECG-> Frozen network <br>->flatening layer <br>-> several FC layers <br>-> classification task & <br>regression tasks 	| Classification<br>(Detection of <br>stressed mothers):<br>AUROC: <br>FELICITy dataset: <br>(mECG) 0.931<br>Public dataset<br>(transfer <br>learning: <br>public+private <br>dataset): <br>(mECG) 0.982<br><br>Regression<br>(Prediction of <br>biomarkers):<br>Public datasets: <br>(mECG)<br>Cortisol: 0.931; <br>FSI: 0.946; <br>PDQ: 0.961; <br>PSS: 0.943. 	| [Link](https://github.com/pritamqu/SSL-ECGv2) 	|
| Self-supervised <br>transfer learning <br>of physiological <br>representations <br>from free-living <br>wearable data 	| Spathis et al.<br>(2021) 	| 1. Label scarcity problem in wearable data;<br>2. Multimodal learning approaches rely on the modalities being used as parallel inputs, limiting the scope of the resulting representations. 	| 1. The new pre-training task forecasts ECG-level quality HR in real-time by only <br>utilizing activity signals, <br>2. Leverage the learned representations of this model to predict personalized <br>health-related outcomes through transfer learning with linear classifers.  	| Set HR responses as the <br>supervisory signal for <br>the activity data, <br>predict personalized <br>health-related outcomes 	| The Fenland <br>study<br>(not public, <br>but can request) 	| Heart rate-noise <br>removal, accelerometer <br>data: auto-calibrated <br>to local gravity, <br>non-wear time was <br>inferred and participants <br>with less than 72 hours <br>of wear were removed. <br>Magnitude of acceleration <br>was calculated through <br>the Euclidean Norm Minus <br>One and the high-passed <br>fltered vector magnitude. <br>Both the accelerometry <br>and ECG signals-summarized <br>to a common time resolution <br>of one observation per 15 <br>seconds. encoded the sensor <br>timestamps using cyclical <br>temporal features. 	| Input: X (sensors), <br>M (metadata), y (target HR)<br>Output : E ÃÉ <br>(user-level embedding), <br>y ÃÉ (target variable)<br>network:<br>pass X through CNN & GRU layers;<br>pass M through reLU layers;<br>concatenate outputs in E;<br>forecast & backpropagate <br>with joint loss L;<br>use trained network to <br>extract embeddings E;<br>aggregate E to the user-level <br>E ÃÉ with average pooling;<br>train a linear model to <br>predict target variables y ÃÉ;<br>Downstream: <br>traditional classifier 	| (A/R/T)=<br>acceleration <br>features/resting <br>heart <br>rate/temporal <br>features<br><br>outcome: sex<br>AUC: <br>step2heart<br>(A/R/T): <br>93.4<br><br>outcome: <br>height<br>AUC: <br>step2heart<br>(A/T): <br>82.1 	| [Link](https://github.com/sdimi/Step2heart) 	|
| Supervised and <br>Self-Supervised <br>Pretraining <br>Based Covid-19 <br>Detection Using <br>Acoustic <br>Breathing/Cough/<br>Speech <br>Signals 	| Chen et al.<br>(2022) 	| The amount of COVID-19 audio data in each sub-task (breath/cough/speech) is still limited, the traditional MFCC feature might be not sufficiently representative for classification tasks. 	| 1. A supervised pre-training method, the model uses breath, cough and <br>speech to train three different models and obtain an average model <br>(used as an initialization model). <br>2. A self-supervised pre-training method, use the pre-tained <br>wav2vec2.0 model to extract high-level features, which are input <br>into the diagnosing model to replace the classic MFCC feature.<br>3. Ensemble the scores obtained by the two models 	| COVID-19 detection <br>(binary classification) 	| DiCOVA-ICASSP<br>2022 challenge <br>dataset 	| The amplitude of the <br>raw waveform is <br>normalized between <br>-1 to 1, cut off silent <br>segments, sound data is <br>downsampled to 16 kHz, <br>forty dimensional MFCC <br>and delta-delta <br>coefficients and <br>extracted with a window <br>of 25 msec audio samples <br>and a hop of 10 msec. <br>use SpecAugment <br>time-frequency mask to <br>augment the data<br>(due to small size <br>of the training data) 	| Model: two bi-directional <br>LSTM layers(encoder) + <br>two linear transformations <br>with a ReLU activation in <br>between(classifier)<br>Supervised pre-train: <br>average model (average <br>three BiLSTM task model) <br>as initialize of classifier.<br>Self-supervised pre-training: <br>wav2vec2.0 model (raw waveform <br>-> a CNN based encoder + a <br>transformer encoder + <br>a quantization model <br>discretizeds the output of <br>feature encoder as targets <br>in the contrastive objective.)<br>Ensemble: train two models, <br>ensemble the scores.  	| AUC: 88.44 <br>on blind test <br>in the <br>fusion track 	| - 	|
| Contrastive <br>Predictive <br>Coding for <br>Anomaly <br>Detection <br>of Fetal <br>Health from <br>the <br>Cardiotocogram 	| de Vries et al.<br>(2022) 	| Low availiability of pathological data along with the high variability in pathologies and a scarcity of available labels 	| 1. Extended the original CPC model by making stochastic, recurrent, <br>and conditioned (upon uterine contractions) predictions, <br>and a custom loss function.<br>2. Based on the detection of out-of-distribution behaviour and <br>deviations from subject-specific behaviour, <br>the proposed model is capable of achieving promising results <br>for identification of suspicious and anomalous FHR events in the CTG. 	| Detection of fetal health <br>from CTG<br>* CTG provides a temporal <br>recording of both the Fetal<br> Heart Rate (FHR) and <br>Uterine Contractions (UC) 	| Dutch STAN trial,<br>a healthy dataset 	| Fatal heart rate <br>signals and toco <br>data were pre-processed <br>to yield a constant <br>sampling frequency <br>of 4Hz by means of <br>linear interpolation <br>and subsequently <br>normalized using <br>the mean, and 98th <br>percentile of the <br>healthy dataset.<br>Before normalization, <br>toco signal was <br>filtered by a zero-phase, <br>4th order Butterworth <br>bandpass-filter with <br>cut-off frequencies <br>at 0.001 and 0.1 Hz.<br>(to eliminate offset <br>and high-frequency noise) 	| Contiditional CPC (Contrastive <br>Predictive Coding) <br>GRU (encoder) + 3 layer MLP <br>(predictor)<br>Use three past windows to <br>predict K=4 <br>Nagetive pair: same signal <br>at different time<br>Training: only use the data <br>of healthy childern. 	| AUC: 0.96 <br>(normal vs <br>anomalous)<br>average <br>correlation <br>coefficient <br>of 0.8+-0.13 <br>with respect <br>to expert <br>annotations 	| - 	|
| Self-Supervised <br>Learning for <br>Anomalous Channel <br>Detection in EEG <br>Graphs: <br>Application to <br>Seizure Analysis 	| Ho et al. <br>(2022) 	| Lack of access to the labeled seizure data 	| 1. A self-supervised method for identifying abnormal brain regions <br>and EEG channels without access to the abnormal <br>class data during the training phase.<br>2. Model brain regions and their connectivities using attributed graphs.<br>3. Employing contrastive and generative learning, propose <br>an augmentation approach to create the positive and negative pairs <br>to form contrastive and generative loss.<br>4. Define a channel-based anomaly score function<br>(linear combination of the contrastive and reconstruction loss)  	| Serizure detection <br>(no access to the <br>seizure data is needed) 	| TUSZ 	| For a given eeg clip, <br>build four types of <br>EEG graphs:<br>Dist-EEG-Graph: <br>use Euclidean distance <br>between electrodes, <br>embed the structure <br>of electrode locations <br>in the graph's <br>adjacency matrix.<br>Rand-EEG-Graph: <br>randomly connection <br>of nodes(assume all <br>electroes are connected <br>and eqyally contribute <br>in brain activities, <br>so every edge has <br>the chance of present <br>in the graph)<br>Corr-EEG-Graph:  <br>functional connectivity <br>between electrodes<br>(cross-correlation function, <br>top-3 neighborhood nodes)<br>DTF-EEG-Graph: <br>directed transfer <br>function graph, functional <br>connectivity of the <br>brian regions. 	| Positive and negative pair <br>sampling: 2 positive & 1 <br>negative sub-graphs for every <br>node in every constructed EEG <br>graph(positive:first selected <br>an electrode as target node, <br>target code anonymize in positvie <br>subgraph(replace its feature <br>vector with an all-zero vector); <br>negative:first find the farthest <br>electrode from the target node)<br>Contrastive learning model: <br>pairs-> GNN encoder -> all embeddings <br>-> take avg over rows -> <br>obtian similiarity -> contrastive loss;<br>Generative learning model: (GNN <br>encoder) -> positive embeddings -> <br>GNN decoder(constracting the target <br>node anonymized in the positive <br>subgraphs, using other node features <br>and edges) -> reconstruction loss; 	| Specificity:<br>EEG_t-CGS: <br>0.989<br>* EEG_t <br>refers to <br>all four <br>graph types <br>are <br>concatenated <br>and fed to <br>the system <br>as the input <br>representing <br>the given <br>EEG clip 	| [Link](https://github.com/Armanfard-Lab/EEG-CGS) 	|
| A Contrastive <br>Predictive <br>Coding-Based <br>Classification <br>Framework for <br>Healthcare <br>Sensor Data 	| Ren et al.<br>(2022) 	| Annotating data consume a large amount of manpower and resources 	| 1. Designing a contrastive predicting coding(CPC)-based pretext task <br>for medical sensor data classification, <br>redesigning the arrangement of positive sample pairs and negative pairs.<br>2. Design a lightweight downstream classification model, <br>further improve the  classification accuracy. 	| 1. Sleep stage classification<br>2. Arrhythmia classification 	| Sleep-EDF,<br>MIT-BIH-SUP 	| Positive sample pair <br>contians 8 different <br>samples belonging <br>to the sample category, <br>and the four left and <br>four right of the negative <br>sample pair belong to the <br>same categories, but the <br>left and right are different <br>categories. 	| Pretext: predict future (GRU)<br>CPC based model<br>Encoder: four blocks, each block: <br>a dense layer, a batch <br>normalization layer, an activation <br>layer, a dense layer.<br>Classification: 2 Conv1D layers,  	| Sleep: <br>macro avg <br>ACC: <br>88.7%<br><br>Arrhythmias:<br>ACC: <br>97.3% 	| - 	|
| A Contrastive <br>Learning Framework <br>for ECG Anomaly <br>Detection 	| Li et al.<br>(2022) 	| 1. Unbalanced data<br>2. Lack robustness due to inconsistent ECG data representation 	| 1. Effective sequence data augmentation methods are introduced to <br>ECG signal abnormal detection, aiming at alleviating category imbalance.<br>2. A new contrastive learning framework that address the challenge of <br>inconsistent data representation during model learning, <br>improve rubustness and accuracy. 	| ECG anomaly detection 	| MIT-BIH <br>arrhythmia <br>dataset,<br>PTB 	| ECG signals were <br>preprocessed and <br>segmented. with each <br>segment corresponding <br>to one heartbeat.<br><br>Augmentation:<br>two methods: <br>BiLSTM-CNN, <br>TimeGAN, <br>(both used in <br>this model) 	| Contrastive learning:<br>Input->BiLSTM&TimeGAN-> Encoder-> <br>Transformer(based on attention <br>mechanism with efficient parallel <br>computing capabilities)-> Non-linear <br>projection head->Maximize similarity<br>Detection:<br>input-> 2 layers of (Conv+Batch Norm)<br>-> max pool -> transformer 	| Arrhythmia: <br>ACC:96.3%<br><br>PTB <br>diagnostic <br>ECG:<br>ACC: 94.5% 	| - 	|
| Listen to your heart: <br>A self-supervised <br>approach for <br>detecting murmur <br>in heart-beat <br>sounds for the <br>Physionet <br>2022 challenge 	| Ballas et al.<br>(2022) 	| Lack of labels in ML tranining 	| Propose two augmentation combinations to construct effective positive pairs 	| Murmur classification, <br>and clinical outcome classification 	| PhysioNet 2016<br>and PhysioNet2022<br>challenge datasets 	| 5 sec is a window, <br>50% overlapping<br><br>Augmentation: <br>View1:250Hz <br>high pass filtering<br>View 2: pollute <br>with uniform noise <br>and then upsampling <br>with 0.5 probability 	| CNN as encoder, 3-layer MLP <br>as prediction head.  	| 0.606 in <br>F-score <br>in murmur <br>classification; <br>0.657 in <br>outcome <br>classification <br>(F1) 	| - 	|
| Weak self-supervised <br>learning for seizure <br>forecasting: <br>a feasibility study 	| Yang et al.<br>(2022) 	| Reduce the burden of manucal labeling 	| Perform a feasibility study on seizure predeciton, which is identified as <br>an ideal test case, as pre-ictal brainwaves are patient-specific, <br>and tailoring models to individual patients is known to improve <br>forecasting performance significantly.  	| Seizure detection <br>and forecasting 	| TUH seizure,<br>EPILEPSIAE dataset,<br>RPAH dataset <br>(pravite) 	| 12s window, ICA and <br>STFT are applied <br>to the EEG before <br>pre-trianed seizure <br>detection.<br>ICA is used for <br>removing EOG artefact. <br>STFT is then applied <br>to the clean EEG with <br>a 250 sample window(1s) <br>and 50% overlap. <br>DC component removed. <br>Same preprocessing <br>used on EEG for <br>prediction. 	| Forecasting model: pre-trained <br>with EPLIEPSIAE, <br>Detection model: pre-trained <br>with TUH, <br>Both model: 3 layers of <br>ConvLSTM, 2 layers of FC<br>(with sigmoid). <br>All three tests, both <br>pseudo-prospectively <br>inference-only real-time <br>tested on the RPAH dataset. 	| Average <br>relative <br>improvement <br>in <br>sensitivity <br>by 14.3%, <br>a reduction <br>in false <br>alarms by <br>19.6% in <br>early <br>seizure <br>forecasting. 	| [Link](https://github.com/NeuroSyd/Weak_learning_for_seizure_forecasting) 	|
| Contrastive <br>Heartbeats: <br>Contrastive <br>Learning for <br>Self-Supervised <br>ECG Representation <br>and Phenotyping 	| Wei et al.<br>(2022) 	| High cost of manual labels 	| Propose a contrastive learning approach, to utilize the periodic and <br>meaningful patterns from ECG. 	| Cardiac arrhythmia classification 	| MIT-BIH,<br>Chapman,<br>private <br>large-scale <br>ECG dataset 	| Exclude samples <br>with <48 bpm, within <br>the ten-second <br>measurement;<br>Positive pair: <br>the anchor heartbeat <br>with a positive <br>heartbeat(sample <br>from the same ECG);<br>Negative pair: <br>the anchor heartbeat <br>with a negative <br>heartbeat(sample <br>from other ECG). 	| Heartbeat extract in the <br>full-length ECG by the <br>Hamilton R-peak segmentation <br>algorithm;<br>Backbone model: Causal CNN;<br>Projector: additional fully <br>connected layer(project the <br>features of the anchor);<br>Loss: multi-similarity loss. 	| Linear <br>evaluation <br>on:<br>MIT-BIH: <br>ACC: <br>89.25;<br>(AUROC=<br>0.9424)<br>Chapman:<br>AUROC: <br>0.920<br><br>Semi-<br>supervised <br>learning:<br>(finetune use <br>partial labels)<br>MIT-BIH: ACC: <br>(50%) 0.9461 	| - 	|
| Practical <br>cardiac events <br>intelligent <br>diagnostic <br>algorithm for <br>wearable <br>12-lead ECG <br>via <br>self-supervised <br>learning on <br>large-scale <br>dataset 	| Yang et al.<br>(2022) 	|  	| 1. Collected 658,948 ECG, 164,538 were diagnosed, <br>and the remaining 493.948 ECGs were without diagnosis.<br>2. Train a Siamese network via contrastive learning, transferred the <br>pretained weights to downstream classification.<br>3. Designed four data augmentation operations for 1D digital myltilead ECG signals. 	| Cardiac events diagnostic <br>(55 cardiac events) 	| CPSC 2018,<br>large-scale <br>ECG dataset<br>(can not be <br>open-scourced) 	| 5th order <br>Butterworth <br>high-pass filter, <br>with the lower <br>cutoff frequency <br>of 0.5 Hz.<br>Data augmentation:<br>1. frequency dropout;<br>2. crop resize;<br>3. cycle mask: <br>detect the position <br>of R peak and segment <br>the same position <br>in each heartbeat <br>to zero;<br>4. channel mask. 	| Momentum contrast(MOCO): <br>an encoder and a momentum <br>encoder, and a projection <br>head at the bottom of each <br>encoder. 	| On CPSC <br>2018: <br>F1 score: <br>0.839 	| [Link](https://github.com/SMU-MedicalVision/ECG-MoCo-Classfication) 	|
| As easy as APC: <br>overcoming missing <br>data and class <br>imbalance in time <br>series with <br>self-supervised <br>learning 	| Wever et al.<br>(2021) 	| High levels of missing data and strong class imbalance 	| Demonstrate how Autoregressive Predictive Coding (APC), <br>can be leveraged to overcome both missing data and class <br>imbalance simultaneouly without strong assumptions. 	| Overcome high missingness <br>and severe class imbalance 	| Synthetic <br>dataset,<br>Physionet <br>challenge<br>2012,<br>menstrual <br>cycle <br>tracking <br>app Clue 	|  	| Encoder: GRU-D (GRU Decay)<br>APC<br>MaskedMSE 	| Physionet2012<br>(binary):<br>AUROC: <br>(GRU-APC <br>without <br>class <br>imbalance <br>method): <br>86.0+-0.5<br><br>Clue dataset<br>(multi-class <br>classification):<br>weighted F1: <br>(GRU-APC): <br>90.7+-0.1 	| [Link](https://github.com/fiorella-wever/APC) 	|
| DeepClean: <br>Self-Supervised <br>Artefact Rejection <br>for Intensive Care <br>Waveform Data Using <br>Deep Generative <br>Learning 	| Edinburgh et al.<br>(2020) 	| Waveform physiological data in ICU are susceptible to artefacts, removal of artefacts reduced bias and uncertainty in clinical assessment and false positive rate of ICU alarms. 	| 1. A prototype self-supervised artifact detection system using a <br>convolutional variational autoencoder deep neural network that <br>avoids manual annotation, requiring only <br>easily-obtained good data for training.<br>2. Can identify regions of artefact with high accuracy. 	| Artefact detection on <br>ICU waveform physiological data 	| ABP waveform data<br>from single <br>anonymised<br>patient <br>throughout a stay 	| Split the data <br>into 100-second <br>windows, <br>normalising <br>across the whole <br>dataset, sampled <br>uniformly within <br>the selected <br>windowto generate <br>10-second sample <br>to join the test <br>set (main contain <br>marked(abnormal <br>marked by expert) <br>sample).  	| VAE with CNNs for both <br>encoder and decoder. 	| Accuracy: <br>(mean)<br>VAE: <br>0.901<br>ROCAUC: <br>0.973 	| [Link](https://github.com/tedinburgh/deepclean) 	|
| SOM-CPC: <br>Unsupervised <br>Contrastive <br>Learning with <br>Self-Organizing <br>Maps for <br>Structured <br>Representations <br>of High-Rate <br>Time Series 	| Huijben et al.<br>(2022) 	| High-dimensional real-world data are difficult to interpret.<br>Deep learning aim to identify this manifold, but do not promote structure nor interpretability. 	| 1. SOM-CPC, suitable for learning structured and interpretable <br>2D representations of high-rate time series by encoding subsequent <br>data windows to a topologically ordered set of quantization vectors.<br>2. Requires far less auxiliary loss function <br>(and associated hyperparameter tuning) 	| Clustering  	| Synthetic <br>dataset,<br>subset 3 <br>of MASS,<br>subset of <br>LibriSpeech <br>dataset 	| For MASS: <br>select three EEG<br> channels(F4, C4, <br>O2), two EOG channels, <br>one chin EMG derivaiton, <br>downsampled to 128Hz, <br>non-overlapping <br>30-second window. <br>Before downsampling, <br>all derivations <br>filtered with a <br>zero-phase 5th order <br>Butterworth band-pass <br>filter, another <br>zero-phase 5th order <br>Butterworth notch filter. <br>Channels normalized <br>within-patient and per <br>channel, yielding mean <br>substraction, and <br>normalization. 	| SOM-CPC<br>Encoder: CNNs <br>(details in appendix) 	| On sleep <br>dataset:<br>Purity: <br>0.79<br>NMI: <br>0.28<br>Cohen's <br>kappa: <br>0.67<br>l_2 smooth: <br>1.22+-0.21<br>TE: 0.042 	| - 	|
| Subject-aware <br>contrastive <br>learning for <br>biosignals 	| Cheng et al.<br>(2020) 	| Dataset for biosignals, limited labels and subjects 	| 1. Apply self-supervised learning to biosignals.<br>2. Develop data augumentation techniques for biosignals.<br>3. Integrate subject awareness into the self-supervised learning framework.<br>    1) subject-specific distribution to compute contrastive loss<br>    2) promoting subject invariance through adversarial training 	| EEG decoding, ECG anomaly detection 	| Physionet <br>Motor Imagery,<br>MIT-BIH <br>arrhythmia 	| Raw EEG/ECG data <br>for input. <br>Data transformations: <br>temporal cutout, <br>temporal delays, <br>noise, bandstop filtering, <br>signal mixing, <br>spatial rotation(exception), <br>spatial shift(exception), <br>sensor dropout, <br>sensor cutout(exception) 	| Encoder and momentum <br>encoder: 1d ResNet with <br>ELU activation and batch <br>normalization.<br>Project head and momentum <br>project head: 4-layer <br>fully-connected network.<br>Linear classification <br>using logistic regression <br>with weight decay. 	| EEG: ACC<br>Intersubject: <br>81.6+-0.8<br>(subject-<br>specific, <br>2 class)<br>Intrasubject: <br>79.6+-2.3<br>(subject-<br>invariant, <br>2 class)<br>ECG:<br>Overall: ACC: <br>subject-<br>specific: <br>93.2+-1.6 	| - 	|
| Sense and learn: <br>Self-supervision <br>for omnipresent <br>sensors 	| Saeed et al. (2021) 	| Non-generalizble representations; Lack of annotations 	| 1. Propose 7 data augmentation schemes<br>2. Design a framework that uses all 7 schemes at the same time to <br>learn generalizable representations 	| EEG, EOG, Heart rate, <br>Skin conductance, accelerometer, <br>gyroscope 	| HHAR, MobiAct, <br>MotionSense, <br>UCI HAR, HAPT, <br>Sleep-EDF, <br>MIT DriveDb, <br>WiFi CSI 	| Blend detection, <br>Fusion magnitude prediction, <br>Feature prediction from <br>masked window, <br>Transformation recognition, <br>Temporal shift prediction, <br>Modality denoising, <br>Odd segment recognition 	| CNN as backbone 	| Kappa <br>scores. <br>HHAR: <br>0.826, <br>MobiAct: <br>0.89, <br>MotionSense: <br>0.907, <br>UCI HAR: <br>0.888; <br>HAPT: <br>0.820; <br>Sleep-EDF: <br>0.702; <br>MIT DriveDb: <br>0.804; <br>WiFi CSI: <br>0.798 	| - 	|
| Self-Supervised <br>Learning From <br>Multi-Sensor Data <br>for Sleep <br>Recognition 	| Zhao et al.<br>(2020) 	| 1. Most of sleep recognition methods are limited to single-task recognition, which only involve single-modal sleep data.<br>2. Shortage and imbalance of sleep samples.  	| 1. Study the problem of sleep recognition at three levels: <br>sleep position/sleep stage recognition, insomnia detection.<br>2. Self-supervised sleep recognition model(SSRM) is proposed for <br>multi-sensor sleep recognition. 	| Sleep position/sleep stage <br>recognition, insomnia detection 	| Sleep <br>Bioradiolocation <br>dataset,<br>Pressure <br>Map dataset,<br>PSG dataset 	| Normalize to [0, 1]<br>For pressure map: <br>rotation and frequency-domain <br>feature extraction to <br>generate temporary labels.<br>For PSG: preprocess and <br>extract four-dimensional <br>feature and count feature. 	|  	| Prediction <br>probability <br>of CRF as <br>the final <br>accuracy.<br>Bio-radar: <br>99.03<br>Pressure-e1: <br>99.55<br>Pressure-e2: <br>98.92<br>PSG-2class: <br>95.91<br>PSG-3class: <br>78.69<br>PSG-4class: <br>71.01 	| - 	|
| Contrastive <br>Embeddind <br>Learning <br>Method for <br>Respiratory <br>Sound <br>Classification 	| Song et al.<br>(2021) 	| 1. Difficulty of collectionand expensive manual annotation, only limited samples availabe.<br>2. Do not explicitly encourage intra-class compactness and inter-class separability between the learned embeddings. 	| Propose a contrastive embedding learning method, input a contrastive tuple, <br>learn the slight differences among similar samples, the easily confused<br> samples are more likely to be identified. 	| Respiratory sound classification 	| ICBHI 2017 	| Resample audio recordings<br> to 16kHz and segment them <br>into respiratory circles <br>according to onsets and offsets. <br>Convert the circles to 46-dimension <br>log Melspectrograms with a window<br> size of 1024 over a 256-sample hop. 	| Augmentation: white noise <br>adding, time shifting, <br>time stretching and pitch <br>shifting<br>Encoder: CNN<br>Classifier: linear layer<br>(logistic regression) 	| ACC: 78.73 	| - 	|
| A Semi-Supervised <br>Algorithm for <br>Improving the <br>Consistency of <br>Crowdsourced <br>Datasets: <br>The COVID-19 Case <br>Study on Respiratory <br>Disorder <br>Classification 	| Orlandic et al.<br>(2022) 	| Labelling inconsistencies and label sparsity in the crowdsourced dataset.<br>(1. potentially noisy user label, 2. often contradictory expert labels) 	| 1. Provide an automated approach for increasing the <br>labeling quality of biosignal datasets.<br>2. The subsample of cough audio recordings identified <br>through our SSL approach was made public 	| Respiratory disorder <br>classification/COVID-19 detection 	| COUGHVID <br>dataset 	| A cough classifier was used to <br>remove non-cough recordings.<br>Normalization (4-order Butterworth<br>lowpass filter; cutoff 6kHz) to<br> reduce high-frequency noise. <br>Isolate each individual cough event. <br>Discard any cough-sound candidates <br>shorter than 200ms, include 200ms <br>before and after the cough candidate<br> in each segment. 	| Supervised(classifier): <br>user model(based on user label), <br>expert 1,2,4 model(based on <br>labels of experts1,2 and 4)<br>SSL model: majority agreement <br>combines the knowledge form <br>both users and experts, to <br>identify a subset of high-confidence <br>samples->used to train on final <br>classifier, the rest were discarded.<br>User: Linear discriminant analysis; <br>Expert1,2,4: Logistic regression; <br>SSL: Logistic regression. 	| SSL: <br>Test AUC<br>0.763 	| - 	|
| BENDR: <br>Using Transformers <br>and a Contrastive <br>Self-Supervised <br>Learning Task to <br>Learn From Massive <br>Amounts of <br>EEG Data 	| Kostas et al. (2021)  	| Less of generability: task-specific model is required 	| Propose a framework with contrastive pre-tranining, <br>it can be used to different tasks/datasets.  	|  	| MMI, BCIC, <br>ERN, SSC, <br>P300 	| Augumentation: CPC (predict the future) 	| CNN+Transformer-based CPC 	| MMI: <br>(86.7 <br>in BAC), <br>BCIC:<br>42.6 in <br>Accuracy, <br>ERN <br>0.65 in <br>AUROC, <br>SSC: <br>0.72 in <br>BAC; <br>P300: <br>0.72 in <br>AUROC 	| - 	|
| Unsupervised <br>Anomaly <br>Detection on <br>Temporal <br>Multiway Data 	| Nguyen et al.<br>(2020) 	| Unsupervised temporal models employed thus far typically work on sequences of feature vectors, and much less on temporal multiway data.  	| 1. Investigate the applications of matrix recurrent neural networks <br>for unsupervised anomaly detection for temporal multiway data.<br>2. Two anomaly detection settings (reconstruction and prediction) are examined, <br>and the empirical results on synthetic data, moving digits <br>and ECG readings are reported. 	| Temporal multiway anomaly <br>detection (looks for <br>irregularities over space-time)<br>Use reconstruction loss:<br>an abnormal sequence does<br>not exhibit the regularities, <br>it is hardly compressible, <br>and thus its reconstruction <br>error is expected to be higher <br>than the error in the normal <br>cases.(if a sequence is regular <br>(normal), the history may contain <br>sufficient information to predict<br>several steps ahead) 	| Synthetic data, <br>MNIST,  <br>MIT-BIH <br>Arrhythmia <br>dataset 	| For MIT-BIH: manually pick 38 subjects<br>(have both MLII and V1 channels a<br>nd no paced beats).<br>For each univariate signal, the raw ECG<br> is detrended by first fitting a 6-order<br> polynomial and then subtracting it <br>from the signal, a 6-order Butterworth <br>bandpass filter with 5Hz and 15Hz range,<br>filtered signals are normalized <br>individually by Z-score normalization.  	| Pre-training:<br>(Matrix) LSTM AutoEncoder model:<br>encoder: matLSTM (compresses X <br>into C by reading one matrix at <br>a timeÔºâ<br>decoder: matLSTM decompresses <br>the memory by predicting one <br>matrix at a time<br>anomaly: reconstruction loss<br>Fine-tuning:<br>(Matrix) LSTM Encoder-Predictor <br>predictive model:<br>anomaly score: <br>mean prediction error 	| matLSTM:<br>(for <br>predicting <br>5 <br>heartbeats)<br>AUC: <br>92.5¬±0.1<br>F1: <br>72.8¬±0.2 	| - 	|
| Self-supervised <br>EEG Representation <br>Learning for <br>Automatic Sleep <br>Staging 	| Yang et al.<br>(2021) 	| 1. Unlabeled and noisy data.<br>2. Existing negative sampling strategies often incur sampling bias. 	| 1. Pretext task: address the inherent limitations of <br>negative sampling in the existing self-supervised methods <br>(e.g., MoCo2, SimCLR3) by leveraging global data statistics.<br>2. strengthen our model with an instance-aware world representation <br>for each sample, where closer samples are assigned larger weights. 	| Sleep stage classification 	| SHHS,<br>Sleep EDF,<br>MGH Sleep 	| Subjects are randomly assigned to<br>the pretext group, training group, <br>test group with different proportions.<br>Augmentation: Bandpass Filtering, <br>Noising, Channel Flipping, Shifting.<br>ContraWR: Contrast with the World <br>Representation(generate an average <br>representation of the dataset, ùíõùíò <br>as the only contrastive information.)<br>ContraWR+: Contrast with <br>Instance-aware World Representation<br>(weighted average of the world/dataset,<br>where the weight is set higher for <br>closer samples.) 	| Classifier: training a separate <br>logistic regression model <br>(on top of the encoder) on data <br>from the training group (during <br>which the encoder is frozen) <br>and test on new recordings.<br>Projector: 2-layer fully <br>connected network.<br>Encoder:  STFT (Short-Time <br>Fourier Transforms) module, <br>resulting STFT spectrogram passes <br>convolutional layer with batch <br>normalization (CNN-based encoder <br>is built on top of the spectrogram) 	| 5 class <br>classification<br>ContraWR+:<br>Sleep EDF:  <br>86.90¬±0.2288<br>SHHS: <br>77.97¬±0.2693<br>MGH Sleep: <br>72.03¬±0.1823<br><br>Baseline: <br>MoCo <br>SimCLR <br>BYOL <br>SimSiam 	| [Link](https://github.com/ycq091044/ContraWR) 	|
| Self-Supervised <br>Learning for <br>Sleep Stage <br>Classification <br>with Predictive <br>and Discriminative <br>Contrastive Coding 	| Xiao et al.<br>(2021) 	| 1. Labeling work is costly and laborious interms of specialist eperience and manual work.<br>2. ground truth lables annotated by sleep experts can also be contradictory, bad influence on label-relied tasks.<br>3. Extracted representations by supervised models are not generalized. 	| 1. The proposed SleepDPC framework is a pioneer to apply SSL <br>on sleep stage classification.<br>2. Proposed two learning principles, Predictive contrastive coding, <br>Discriminative contrastive coding, enable extract high-level semantics<br>(underlying rhythms and patterns) from raw EEG. 	| Sleep stage classification  	| Sleep-EDF,<br>ISRUC 	| Combining PCC and DCC:<br>PCC(predictive contrastive coding): <br>other representation(at different <br>timestep) in the mini-batch are<br> considered as "unrelated"(negative), <br>DCC(discriminative contrastive coding):<br>representations in different segment<br> of a mini-batch are temporally <br>distant, as negative pair.  	| Pre-train:<br>encoder: CNN<br>aggregator: GRU and LSTM<br>predictor: not mentioned<br>Fine-tuning:<br>encoder and aggregator are frozen.<br>classifier: one-layer <br>fully-connected network. 	| SleepDPC<br>(10% labels)<br>SleepEDF:<br>Accuracy:<br>0.701¬±0.008<br>F1-macro:<br>0.640¬±0.015<br><br>ISRUC:<br>Accuracy:<br>0.536¬±0.015<br>F1-macro:<br>0.489¬±0.018 	| [Link](https://github.com/larryshaw0079/SleepDPC) 	|
| CoSleep: <br>A Multi-View <br>Representation <br>Learning Framework <br>for Self-Supervised <br>Learning of Sleep <br>Stage <br>Classification 	| Ye et al.<br>(2022) 	| 1. Large-scale labeled datasets are still hard to acquire<br>2. DPC operates discrimination at an instance level(treats each instance as a single class); seasonality of time-searies indicates that distant instances can be semantically close 	| 1. Novel co-training scheme by exploiting complementary information from <br>time and frequency view of physiological signals to mine more positive samples. <br>2. Extend the framework with a memory module, <br>implemented by a queue and a moving-averaged encoder, <br>to enlarge the pool of negative candidates. 	| Sleep stage classification 	| SleepEDF,<br>ISRUC 	| Use multi-instance infoNCE loss,<br>calculating loss function using <br>multiple positive samples. Select <br>the Top-K positive samples by time- <br>and frequency-domain similarities. 	| Pre-training: <br>Two encoders: CNN with residual <br>connections (ResNet); <br>aggregator: GRU/LSTM<br><br>Finetuning:<br>encoder and aggregator are freezed.<br>classifier: one-layer <br>fully-connected network.(10%label) 	| CoSleep:<br>SleepEDF:<br>ACC:<br>0.716¬±0.043<br>F1:<br>0.558¬±0.03<br><br>ISRUC:<br>ACC:<br>0.579¬±0.051<br>F1: <br>0.501¬±0.056 	| [Link](https://github.com/larryshaw0079/CoSleep) 	|
| A Self-Supervised <br>Learning Based <br>Channel Attention <br>MLP-Mixer Network <br>for Motor <br>Imagery Decoding 	| He et al.<br>(2022) 	| 1. CNN for MI EEG decoding 's performance is generally limited due to the small size sample problem.<br>2. To address 1, EEG trials segment into small slices, usually inevitably losses the longrange dependencies of temporal information. 	| 1. A new EEG slice prediction task as pretext task to capture <br>the long-range information in time domain.<br>2. In the downstream task, a MLP-Mixer is for classification <br>task for signal(rather than image)<br>3. An attention mechanism is integrated into MLP-Mixer to <br>estimate the importance of each EEG channel. 	| Motor Imagery (movement <br>imagination classification) 	| MI-2 Dataset,<br>BCIC-IV-2A Dataset 	| 150-time points sliding window <br>(overlap of 10 points), <br>z-score normalization <br>on each slice. 	| Pretext task: 3 adjacent EEG slices <br>-> local encoder(1D CNN) -> <br>concatenation -> LSTM layers -> <br>conv and linear -> predicted EEG slice<br>Downstream task: EEG slice -> <br>Local encoder(with Weights from pretext) <br>-> Channel-attention MPL-Mixer(CAU&TMU) <br>-> Classifier(global average pooling <br>-> Linear layer -> Softmax -> Prediction) 	| MI-2: <br>ACC: <br>78.5¬±0.64<br>F1: <br>78.39¬±0.67<br><br>BCI-IV-2A:<br>ACC: <br>79.43¬±1.73<br>F1: <br>79.42¬±1.74 	| - 	|
| Self-supervised <br>Contrastive <br>Learning for <br>EEG-based <br>Sleep Staging 	| Jiang et al.<br>(2021) 	| Data shortage of supervised learning 	| Propose a self-supervised contrastive learning for EEG <br>sleep staging classification, measures the feature <br>similarity if transformed signal pairs. 	| EEG-based sleep staging <br>classification 	| Sleep-edf,<br>Sleep-edfx,<br>Dod-O,<br>Dod-H 	| Transformations:<br>Sleep-edf: crop&resize + permutation;<br>crop&resize + crop&resize.<br>together: crop&resize + time warping;<br>crop&resize + permutation 	| SSL training:<br>input: transformed unlabelled data; <br>encoder: ResNet based; <br>positive pair: homologous pair; <br>negative pairs: others.<br>Fine tuning: classifier: FC layers. 	| Healthy<br>subjects: <br>Acc: 88.16; <br>F1: 81.96<br><br>Healthy <br>and subjects <br>with sleep <br>disorders:<br>Acc: 84.42; <br>F1: 78.95 	| [Link](https://github.com/XueJiang16/ssl-torch) 	|
| Self-Supervised <br>Contrastive <br>Pre-Training For <br>Time Series via <br>Time-Frequency <br>Consistency 	| Zhang et al.<br>(2022) 	| Lack of data labels 	| Propose the assumption of Time-Frequency Consistency: <br>the information is taken in the time domain and in <br>the frequency domain is equivalent. 	| Sleep disorder, <br>Eplipsy detection, <br>Mechanical fault detection, <br>etc. 	|  	| Time domain: shift, jittering, etc. <br>Frequency domain: adding/removing <br>frequency component 	| CNN-based encoder, <br>MLP-based projector 	| - 	| [Link](https://github.com/mims-harvard/TFC-pretraining) 	|


<p align="center"><a href="#top"><img src="https://img.shields.io/static/v1?label&message=back+to+top&color=7E3ACE&style=flat&logo" alt="back to top" /></a></p>
